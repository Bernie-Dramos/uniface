{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üîê Face Verification: One-to-One Face Comparison\n",
        "\n",
        "<div style=\"display:flex; flex-wrap:wrap; align-items:center;\">\n",
        "  <a style=\"margin-right:10px; margin-bottom:6px;\" href=\"https://pepy.tech/projects/uniface\"><img alt=\"PyPI Downloads\" src=\"https://static.pepy.tech/badge/uniface\"></a>\n",
        "  <a style=\"margin-right:10px; margin-bottom:6px;\" href=\"https://pypi.org/project/uniface/\"><img alt=\"PyPI Version\" src=\"https://img.shields.io/pypi/v/uniface.svg\"></a>\n",
        "  <a style=\"margin-right:10px; margin-bottom:6px;\" href=\"https://opensource.org/licenses/MIT\"><img alt=\"License\" src=\"https://img.shields.io/badge/License-MIT-blue.svg\"></a>\n",
        "  <a style=\"margin-bottom:6px;\" href=\"https://github.com/yakhyo/uniface\"><img alt=\"GitHub Stars\" src=\"https://img.shields.io/github/stars/yakhyo/uniface.svg?style=social\"></a>\n",
        "</div>\n",
        "\n",
        "**UniFace** is a lightweight, production-ready, all-in-one face analysis library built on ONNX Runtime.\n",
        "\n",
        "üîó **GitHub**: [github.com/yakhyo/uniface](https://github.com/yakhyo/uniface) | üìö **Docs**: [yakhyo.github.io/uniface](https://yakhyo.github.io/uniface)\n",
        "\n",
        "---\n",
        "\n",
        "## üìñ Overview\n",
        "\n",
        "This notebook demonstrates **face verification** - comparing two faces to determine if they belong to the same person:\n",
        "\n",
        "- ‚úÖ Compare face embeddings using cosine similarity\n",
        "- ‚úÖ Set thresholds for same/different person decisions\n",
        "- ‚úÖ Batch compare multiple face pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£ Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q uniface\n",
        "\n",
        "import os\n",
        "import urllib.request\n",
        "\n",
        "os.makedirs('assets/test_images', exist_ok=True)\n",
        "\n",
        "BASE_URL = \"https://raw.githubusercontent.com/yakhyo/uniface/main/assets\"\n",
        "images = [\"test_images/image0.jpg\", \"test_images/image1.jpg\", \"test_images/image2.jpg\"]\n",
        "\n",
        "for img in images:\n",
        "    if not os.path.exists(f'assets/{img}'):\n",
        "        urllib.request.urlretrieve(f\"{BASE_URL}/{img}\", f\"assets/{img}\")\n",
        "        print(f\"‚úì Downloaded {img}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2Ô∏è‚É£ Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import uniface\n",
        "from uniface import FaceAnalyzer\n",
        "from uniface.detection import RetinaFace\n",
        "from uniface.recognition import ArcFace\n",
        "\n",
        "print(f\"UniFace version: {uniface.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3Ô∏è‚É£ Initialize Face Analyzer\n",
        "\n",
        "We need both detection and recognition models for face verification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "analyzer = FaceAnalyzer(\n",
        "    detector=RetinaFace(confidence_threshold=0.5),\n",
        "    recognizer=ArcFace()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4Ô∏è‚É£ Load and Analyze Two Faces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_path1 = 'assets/test_images/image0.jpg'\n",
        "image_path2 = 'assets/test_images/image1.jpg'\n",
        "\n",
        "image1 = cv2.imread(image_path1)\n",
        "image2 = cv2.imread(image_path2)\n",
        "\n",
        "faces1 = analyzer.analyze(image1)\n",
        "faces2 = analyzer.analyze(image2)\n",
        "\n",
        "print(f'‚úì Detected {len(faces1)} face(s) in image 1')\n",
        "print(f'‚úì Detected {len(faces2)} face(s) in image 2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5Ô∏è‚É£ Display the Two Faces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "axes[0].imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
        "axes[0].set_title('Image 1')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
        "axes[1].set_title('Image 2')\n",
        "axes[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6Ô∏è‚É£ Compute Face Similarity\n",
        "\n",
        "Face similarity is computed using **cosine similarity** between face embeddings:\n",
        "- **Range**: -1 to 1 (higher = more similar)\n",
        "- **Threshold**: 0.6 is commonly used (above = same person)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if faces1 and faces2:\n",
        "    face1 = faces1[0]\n",
        "    face2 = faces2[0]\n",
        "\n",
        "    similarity = face1.compute_similarity(face2)\n",
        "    print(f'Similarity: {similarity:.4f}')\n",
        "else:\n",
        "    print('‚ö† Error: Could not detect faces')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7Ô∏è‚É£ Make Verification Decision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "THRESHOLD = 0.6\n",
        "\n",
        "if faces1 and faces2:\n",
        "    is_same_person = similarity > THRESHOLD\n",
        "\n",
        "    print(f'üìä Similarity: {similarity:.4f}')\n",
        "    print(f'üìè Threshold: {THRESHOLD}')\n",
        "    print(f'üéØ Result: {\"‚úÖ Same person\" if is_same_person else \"‚ùå Different people\"}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8Ô∏è‚É£ Batch Comparison: Multiple Pairs\n",
        "\n",
        "Compare multiple face pairs efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_pairs = [\n",
        "    ('assets/test_images/image0.jpg', 'assets/test_images/image1.jpg'),\n",
        "    ('assets/test_images/image0.jpg', 'assets/test_images/image2.jpg'),\n",
        "    ('assets/test_images/image1.jpg', 'assets/test_images/image2.jpg'),\n",
        "]\n",
        "\n",
        "print('Comparing multiple pairs:')\n",
        "print('-' * 45)\n",
        "for img1_path, img2_path in image_pairs:\n",
        "    img1 = cv2.imread(img1_path)\n",
        "    img2 = cv2.imread(img2_path)\n",
        "\n",
        "    faces_a = analyzer.analyze(img1)\n",
        "    faces_b = analyzer.analyze(img2)\n",
        "\n",
        "    if faces_a and faces_b:\n",
        "        sim = faces_a[0].compute_similarity(faces_b[0])\n",
        "        img1_name = img1_path.split('/')[-1]\n",
        "        img2_name = img2_path.split('/')[-1]\n",
        "        status = \"‚úÖ Match\" if sim > THRESHOLD else \"‚ùå No match\"\n",
        "        print(f'{img1_name} vs {img2_name}: {sim:.4f} {status}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìù Summary\n",
        "\n",
        "| Feature | Description |\n",
        "|---------|-------------|\n",
        "| **Similarity Range** | -1 to 1 (cosine similarity) |\n",
        "| **Default Threshold** | 0.6 (same person if above) |\n",
        "| **Method** | `face.compute_similarity(other_face)` |\n",
        "| **Use Case** | Identity verification, access control |\n",
        "\n",
        "### Threshold Guidelines\n",
        "\n",
        "| Threshold | Use Case |\n",
        "|-----------|----------|\n",
        "| **0.5** | Lenient matching (more false positives) |\n",
        "| **0.6** | Balanced (recommended default) |\n",
        "| **0.7+** | Strict matching (fewer false positives) |\n",
        "\n",
        "---\n",
        "\n",
        "## üîó Next Steps\n",
        "\n",
        "- **Face Search**: Find a person in a crowd ‚Üí [04_face_search.ipynb](./04_face_search.ipynb)\n",
        "- **Face Analysis**: Age, gender prediction ‚Üí [05_face_analyzer.ipynb](./05_face_analyzer.ipynb)\n",
        "- **Full Documentation**: [yakhyo.github.io/uniface](https://yakhyo.github.io/uniface)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
