{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üë§ Face Analysis: Age & Gender Prediction\n",
        "\n",
        "<div style=\"display:flex; flex-wrap:wrap; align-items:center;\">\n",
        "  <a style=\"margin-right:10px; margin-bottom:6px;\" href=\"https://pepy.tech/projects/uniface\"><img alt=\"PyPI Downloads\" src=\"https://static.pepy.tech/badge/uniface\"></a>\n",
        "  <a style=\"margin-right:10px; margin-bottom:6px;\" href=\"https://pypi.org/project/uniface/\"><img alt=\"PyPI Version\" src=\"https://img.shields.io/pypi/v/uniface.svg\"></a>\n",
        "  <a style=\"margin-right:10px; margin-bottom:6px;\" href=\"https://opensource.org/licenses/MIT\"><img alt=\"License\" src=\"https://img.shields.io/badge/License-MIT-blue.svg\"></a>\n",
        "  <a style=\"margin-bottom:6px;\" href=\"https://github.com/yakhyo/uniface\"><img alt=\"GitHub Stars\" src=\"https://img.shields.io/github/stars/yakhyo/uniface.svg?style=social\"></a>\n",
        "</div>\n",
        "\n",
        "**UniFace** is a lightweight, production-ready, all-in-one face analysis library built on ONNX Runtime.\n",
        "\n",
        "üîó **GitHub**: [github.com/yakhyo/uniface](https://github.com/yakhyo/uniface) | üìö **Docs**: [yakhyo.github.io/uniface](https://yakhyo.github.io/uniface)\n",
        "\n",
        "---\n",
        "\n",
        "## üìñ Overview\n",
        "\n",
        "This notebook demonstrates **comprehensive face analysis** using the FaceAnalyzer class:\n",
        "\n",
        "- ‚úÖ Detect faces with bounding boxes and landmarks\n",
        "- ‚úÖ Predict age and gender attributes\n",
        "- ‚úÖ Extract face embeddings for recognition\n",
        "- ‚úÖ Compare faces using similarity scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£ Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q uniface\n",
        "\n",
        "import os\n",
        "import urllib.request\n",
        "\n",
        "os.makedirs('assets/test_images', exist_ok=True)\n",
        "\n",
        "BASE_URL = \"https://raw.githubusercontent.com/yakhyo/uniface/main/assets\"\n",
        "images = [\"test_images/image0.jpg\", \"test_images/image1.jpg\", \"test_images/image2.jpg\"]\n",
        "\n",
        "for img in images:\n",
        "    if not os.path.exists(f'assets/{img}'):\n",
        "        urllib.request.urlretrieve(f\"{BASE_URL}/{img}\", f\"assets/{img}\")\n",
        "        print(f\"‚úì Downloaded {img}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2Ô∏è‚É£ Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import uniface\n",
        "from uniface import FaceAnalyzer\n",
        "from uniface.detection import RetinaFace\n",
        "from uniface.recognition import ArcFace\n",
        "from uniface.attribute import AgeGender\n",
        "from uniface.visualization import draw_detections\n",
        "\n",
        "print(f\"UniFace version: {uniface.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3Ô∏è‚É£ Initialize FaceAnalyzer\n",
        "\n",
        "The FaceAnalyzer combines **detection**, **recognition**, and **attribute prediction** in one class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "analyzer = FaceAnalyzer(\n",
        "    detector=RetinaFace(confidence_threshold=0.5),\n",
        "    recognizer=ArcFace(),\n",
        "    age_gender=AgeGender()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4Ô∏è‚É£ Analyze Faces in Multiple Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_paths = [\n",
        "    'assets/test_images/image0.jpg',\n",
        "    'assets/test_images/image1.jpg',\n",
        "    'assets/test_images/image2.jpg',\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for image_path in image_paths:\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f'‚ö† Error: Could not read {image_path}')\n",
        "        continue\n",
        "\n",
        "    faces = analyzer.analyze(image)\n",
        "    print(f'\\nüì∑ {image_path.split(\"/\")[-1]}: Detected {len(faces)} face(s)')\n",
        "\n",
        "    for i, face in enumerate(faces, 1):\n",
        "        print(f'   Face {i}: {face.sex}, {face.age}y')\n",
        "\n",
        "    vis_image = image.copy()\n",
        "    bboxes = [f.bbox for f in faces]\n",
        "    scores = [f.confidence for f in faces]\n",
        "    landmarks = [f.landmarks for f in faces]\n",
        "    draw_detections(image=vis_image, bboxes=bboxes, scores=scores, landmarks=landmarks, vis_threshold=0.5, fancy_bbox=True)\n",
        "\n",
        "    results.append((image_path, cv2.cvtColor(vis_image, cv2.COLOR_BGR2RGB), faces))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5Ô∏è‚É£ Visualize Results with Attribute Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, len(results), figsize=(15, 8), gridspec_kw={'height_ratios': [4, 1]})\n",
        "\n",
        "for idx, (path, vis_image, faces) in enumerate(results):\n",
        "    axes[0, idx].imshow(vis_image)\n",
        "    axes[0, idx].axis('off')\n",
        "\n",
        "    axes[1, idx].axis('off')\n",
        "    info_text = f'{len(faces)} face(s)\\n'\n",
        "    for i, face in enumerate(faces, 1):\n",
        "        info_text += f'Face {i}: {face.sex}, {face.age}y\\n'\n",
        "\n",
        "    axes[1, idx].text(0.5, 0.5, info_text, ha='center', va='center', fontsize=11, family='monospace',\n",
        "                      bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6Ô∏è‚É£ Access All Face Attributes\n",
        "\n",
        "Each Face object contains detection, recognition, and attribute data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_, _, faces = results[0]\n",
        "if faces:\n",
        "    face = faces[0]\n",
        "\n",
        "    print('üìã Face Attributes:')\n",
        "    print(f'   ‚Ä¢ Bounding box: {face.bbox.astype(int).tolist()}')\n",
        "    print(f'   ‚Ä¢ Confidence: {face.confidence:.3f}')\n",
        "    print(f'   ‚Ä¢ Landmarks shape: {face.landmarks.shape}')\n",
        "    print(f'   ‚Ä¢ Age: {face.age} years')\n",
        "    print(f'   ‚Ä¢ Gender: {face.sex}')\n",
        "    print(f'   ‚Ä¢ Embedding shape: {face.embedding.shape}')\n",
        "    print(f'   ‚Ä¢ Embedding dimension: {face.embedding.shape[1]}D')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7Ô∏è‚É£ Compare Face Similarity\n",
        "\n",
        "Use face embeddings to compute similarity between detected faces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(results) >= 2:\n",
        "    face1 = results[0][2][0]\n",
        "    face2 = results[1][2][0]\n",
        "\n",
        "    similarity = face1.compute_similarity(face2)\n",
        "    is_same = similarity > 0.6\n",
        "    \n",
        "    print(f'üîÑ Comparing faces from first two images:')\n",
        "    print(f'   ‚Ä¢ Similarity: {similarity:.4f}')\n",
        "    print(f'   ‚Ä¢ Same person: {\"‚úÖ Yes\" if is_same else \"‚ùå No\"} (threshold=0.6)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìù Summary\n",
        "\n",
        "| Attribute | Description |\n",
        "|-----------|-------------|\n",
        "| `face.bbox` | Bounding box `[x1, y1, x2, y2]` |\n",
        "| `face.confidence` | Detection confidence (0-1) |\n",
        "| `face.landmarks` | 5-point facial landmarks |\n",
        "| `face.age` | Predicted age (years) |\n",
        "| `face.sex` | Predicted gender (\"Male\"/\"Female\") |\n",
        "| `face.embedding` | 512D face embedding for recognition |\n",
        "\n",
        "### Methods\n",
        "\n",
        "| Method | Description |\n",
        "|--------|-------------|\n",
        "| `analyzer.analyze(image)` | Full analysis (detect + recognize + attributes) |\n",
        "| `face.compute_similarity(other)` | Cosine similarity between two faces |\n",
        "\n",
        "---\n",
        "\n",
        "## üîó Next Steps\n",
        "\n",
        "- **Face Parsing**: Semantic segmentation ‚Üí [06_face_parsing.ipynb](./06_face_parsing.ipynb)\n",
        "- **Face Anonymization**: Blur faces for privacy ‚Üí [07_face_anonymization.ipynb](./07_face_anonymization.ipynb)\n",
        "- **Full Documentation**: [yakhyo.github.io/uniface](https://yakhyo.github.io/uniface)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
