{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéØ Face Detection and Alignment with UniFace\n",
        "\n",
        "<div style=\"display:flex; flex-wrap:wrap; align-items:center;\">\n",
        "  <a style=\"margin-right:10px; margin-bottom:6px;\" href=\"https://pepy.tech/projects/uniface\"><img alt=\"PyPI Downloads\" src=\"https://static.pepy.tech/badge/uniface\"></a>\n",
        "  <a style=\"margin-right:10px; margin-bottom:6px;\" href=\"https://pypi.org/project/uniface/\"><img alt=\"PyPI Version\" src=\"https://img.shields.io/pypi/v/uniface.svg\"></a>\n",
        "  <a style=\"margin-right:10px; margin-bottom:6px;\" href=\"https://opensource.org/licenses/MIT\"><img alt=\"License\" src=\"https://img.shields.io/badge/License-MIT-blue.svg\"></a>\n",
        "  <a style=\"margin-bottom:6px;\" href=\"https://github.com/yakhyo/uniface\"><img alt=\"GitHub Stars\" src=\"https://img.shields.io/github/stars/yakhyo/uniface.svg?style=social\"></a>\n",
        "</div>\n",
        "\n",
        "**UniFace** is a lightweight, production-ready, all-in-one face analysis library built on ONNX Runtime.\n",
        "\n",
        "üîó **GitHub**: [github.com/yakhyo/uniface](https://github.com/yakhyo/uniface) | üìö **Docs**: [yakhyo.github.io/uniface](https://yakhyo.github.io/uniface)\n",
        "\n",
        "---\n",
        "\n",
        "## üìñ Overview\n",
        "\n",
        "This notebook demonstrates **face alignment** - a crucial preprocessing step for face recognition:\n",
        "\n",
        "- ‚úÖ Detect faces and extract 5-point landmarks\n",
        "- ‚úÖ Align faces using similarity transformation\n",
        "- ‚úÖ Generate normalized 112√ó112 face crops ready for recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£ Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q uniface\n",
        "\n",
        "import os\n",
        "import urllib.request\n",
        "\n",
        "os.makedirs('assets/test_images', exist_ok=True)\n",
        "\n",
        "BASE_URL = \"https://raw.githubusercontent.com/yakhyo/uniface/main/assets\"\n",
        "images = [\"test_images/image0.jpg\", \"test_images/image1.jpg\", \"test_images/image2.jpg\",\n",
        "          \"test_images/image3.jpg\", \"test_images/image4.jpg\"]\n",
        "\n",
        "for img in images:\n",
        "    if not os.path.exists(f'assets/{img}'):\n",
        "        urllib.request.urlretrieve(f\"{BASE_URL}/{img}\", f\"assets/{img}\")\n",
        "        print(f\"‚úì Downloaded {img}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2Ô∏è‚É£ Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import uniface\n",
        "from uniface.detection import RetinaFace\n",
        "from uniface.face_utils import face_alignment\n",
        "from uniface.visualization import draw_detections\n",
        "\n",
        "print(f\"UniFace version: {uniface.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3Ô∏è‚É£ Initialize the Detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "detector = RetinaFace(\n",
        "    confidence_threshold=0.5,\n",
        "    nms_threshold=0.4,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4Ô∏è‚É£ Load Images and Perform Detection + Alignment\n",
        "\n",
        "We'll process multiple images to demonstrate the alignment pipeline:\n",
        "1. **Detect** faces and extract landmarks\n",
        "2. **Align** faces using 5-point landmarks\n",
        "3. **Crop** to 112√ó112 (standard size for face recognition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_paths = [\n",
        "    'assets/test_images/image0.jpg',\n",
        "    'assets/test_images/image1.jpg',\n",
        "    'assets/test_images/image2.jpg',\n",
        "    'assets/test_images/image3.jpg',\n",
        "    'assets/test_images/image4.jpg',\n",
        "]\n",
        "\n",
        "original_images = []\n",
        "detection_images = []\n",
        "aligned_images = []\n",
        "\n",
        "for image_path in image_paths:\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f'‚ö† Error: Could not read {image_path}')\n",
        "        continue\n",
        "\n",
        "    faces = detector.detect(image)\n",
        "    if not faces:\n",
        "        print(f'‚ö† No faces detected in {image_path}')\n",
        "        continue\n",
        "\n",
        "    bbox_image = image.copy()\n",
        "    bboxes = [f.bbox for f in faces]\n",
        "    scores = [f.confidence for f in faces]\n",
        "    landmarks = [f.landmarks for f in faces]\n",
        "    draw_detections(image=bbox_image, bboxes=bboxes, scores=scores, landmarks=landmarks, vis_threshold=0.6, fancy_bbox=True)\n",
        "\n",
        "    first_landmarks = faces[0].landmarks\n",
        "    aligned_image, _ = face_alignment(image, first_landmarks, image_size=112)\n",
        "\n",
        "    original_images.append(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    detection_images.append(cv2.cvtColor(bbox_image, cv2.COLOR_BGR2RGB))\n",
        "    aligned_images.append(cv2.cvtColor(aligned_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "print(f'‚úì Processed {len(original_images)} images')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5Ô∏è‚É£ Visualize Results\n",
        "\n",
        "**Row 1**: Original images  \n",
        "**Row 2**: Detection with landmarks  \n",
        "**Row 3**: Aligned 112√ó112 face crops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(3, len(original_images), figsize=(15, 10))\n",
        "\n",
        "row_titles = ['Original', 'Detection', 'Aligned (112√ó112)']\n",
        "\n",
        "for row, images in enumerate([original_images, detection_images, aligned_images]):\n",
        "    for col, img in enumerate(images):\n",
        "        axes[row, col].imshow(img)\n",
        "        axes[row, col].axis('off')\n",
        "        if col == 0:\n",
        "            axes[row, col].set_title(row_titles[row], fontsize=12, loc='left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìù Summary\n",
        "\n",
        "| Feature | Description |\n",
        "|---------|-------------|\n",
        "| **Detection** | `detect()` returns `Face` objects with `bbox`, `confidence`, `landmarks` |\n",
        "| **Landmarks** | 5-point facial landmarks (2 eyes, nose, 2 mouth corners) |\n",
        "| **Alignment** | `face_alignment()` uses similarity transform to normalize faces |\n",
        "| **Output Size** | Default 112√ó112 (standard for recognition models) |\n",
        "\n",
        "### Why Face Alignment Matters\n",
        "\n",
        "1. **Consistency**: Normalized face positions improve recognition accuracy\n",
        "2. **Scale invariance**: All faces are scaled to the same size\n",
        "3. **Rotation correction**: Faces are rotated to a canonical orientation\n",
        "\n",
        "---\n",
        "\n",
        "## üîó Next Steps\n",
        "\n",
        "- **Face Verification**: Compare two faces ‚Üí [03_face_verification.ipynb](./03_face_verification.ipynb)\n",
        "- **Face Search**: Find a person in a group ‚Üí [04_face_search.ipynb](./04_face_search.ipynb)\n",
        "- **Full Documentation**: [yakhyo.github.io/uniface](https://yakhyo.github.io/uniface)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
